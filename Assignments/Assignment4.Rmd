---
title: "Assignment 4"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FinTS)
library(tseries)
library(aTSA)
library(urca)
library(lmtest)
library(egcm)
library(haven)
library(tinytex)
```

## Question 1: Cointegration 

|   The block of code situated below just shows how I imported the data into R and transformed both the r1 and r3 into time series data. However, given the fact that the data given is a stata file I am unsure if it was necessary for us to transform the data into a time series data to begin with. I tested for a unit root in the r1 and r3 series using the augmented Dickey Fuller test on both the untransformed, the original imported data, and the transformed data, that I transformed in the block of code underneath, to see if there was a difference in the results. The results were the same, leading me to conclude that the original data was already a time series data.   

```{r, results='hide'}

irates <- read_dta("G:/Github/TimeSeries/Data/irates.dta")
attach(irates)
ts(r1)
ts(r3)
```

### A) 
Testing for a unit root in r1 using several augmented Dickey Fuller tests.
```{r}
tseries::adf.test(r1,k=0) # Dickey Fuller Test: no unit root
tseries::adf.test(r1,k=1) # Augmented DF Test with 1 lag: no unit root
tseries::adf.test(r1,k=2) # Augmented DF Test with 2 lags: no unit root
tseries::adf.test(r1,k=3) # Augmented DF Test with 3 lags: unit root
tseries::adf.test(r1,k=4) # Augmented DF Test with 4 lags: unit root
tseries::adf.test(r1)     # Augmented DF Test with upper bounds lags: unit root
```

|   When we run the augmented Dickey Fuller tests with 0,1 and 2 lags, we reject the null hypothesis that the time series data contains a unit root. However, when we we increase the number of lags to 3 or more, we fail to reject the null that the time series data has a unit root. Looking at the ACF of the time series, the graph below, I would say that the more lags that we have included are better, thus the r1 time series does indeed have a unit root.  


```{r}
acf(r1)
```

### B)
|   Testing for a unit root in r3 using several augmented Dickey Fuller tests.
```{r}
tseries::adf.test(r3,k=0) # Dickey Fuller Test: unit root
tseries::adf.test(r3,k=1) # Augmented DF Test with 1 lag: no unit root
tseries::adf.test(r3,k=2) # Augmented DF Test with 2 lags: unit root
tseries::adf.test(r3,k=3) # Augmented DF Test with 3 lags: unit root
tseries::adf.test(r3,k=4) # Augmented DF Test with 4 lags: unit root
tseries::adf.test(r3)     # Augmented DF Test with upper bounds lags: unit root
```

|   What is interesting here is that when I run the simple Dickey Fuller test and the augmented DF test with 2 or more lags, I find that I consistently fail to reject the null hypothesis that there is a unit root present in the time series. Looking at the ACF of the time series, I do not see why that would be the case. Either way, we can conclude that the there is a unit root in the r3 time series data.     


```{r}
acf(r3)
```

Performing a regression by OLS explaining r1 from r3 and testing for co-integration.

```{r}
Reg1 <- lm(r1~r3)
Reg1Resid <- Reg1$residuals
tseries::adf.test(Reg1Resid,k=0) # no unit root
tseries::adf.test(Reg1Resid,k=1) # no unit root
tseries::adf.test(Reg1Resid,k=2) # no unit root
tseries::adf.test(Reg1Resid,k=3) # no unit root
tseries::adf.test(Reg1Resid)     # no unit root. Long Run Relationship between r3 and r1. 
```


### C)

|   Performing a regression by OLS explaining r3 from r1 and testing for co-integration.
```{r}
Reg2 <- lm(r3~r1)
Reg2Resid <- Reg2$residuals
tseries::adf.test(Reg2Resid,k=0) # no unit root
tseries::adf.test(Reg2Resid,k=1) # no unit root
tseries::adf.test(Reg2Resid,k=2) # no unit root
tseries::adf.test(Reg2Resid,k=3) # no unit root
tseries::adf.test(Reg2Resid)     # no unit root. Long Run Relationship between r3 and r1. 
```

### D)
|   Cointegration when there is a stable relationship between two unit root time series. In this case we do want to regress the unit root time series on the other one because this regression would not be spurious. The reason why we would want to do this is because the estimate for $\beta$ with OLS is not only consistent, but it is "super consistent" meaing that it converges to the true $\beta$ much faster than usual asymptotic. In short, cointegrated series have stochastic trend in common.
  
|   In this case, we can see that the r1 and r3 time series data contain unit roots from the adf test. We think that there exists a linear relationship between the two since they are both interest rates. To test this theory, we run a regression of r1 on r3 and vice versa, we take the residuals, which represent the equilibrium error, to see if they reject the null hypothesis that the residuals contain a unit root. As we can see from the results, the residuals we consitently reject the null hypothesis that there is a unit root in the residuals. IF the residuals are stationary, i.e. do not contain a unit root, then if r1 or r3 deviate from the equilibrium then it would eventually get back to it.   

|   However, it is important to note that when we do the augmented DF tests on the residuals we look at the DF value, not necessarily the p-value, and compare it to the Davidson and Mackinnon Cointegrated Regression Dickey Fuller critical value table. The reason is that the OLS chooses small variance in the residuals leading us to reject the null hypothesis more often than not. In either case, no matter the number of lags, we get a DF statistic less than -3.90, meaning that we reject the null hypothesis. 

|   What do you mean interpret results intuitively. 
  
|   In this context, the interest rate spread moves over time but will eventually settle at its mean. 


## Question 2: 

### I) Cholesky Decomposition

  A. The vector of structural shocks is: 
  $$\begin{bmatrix}
  \epsilon_{1t}\\
  \epsilon_{2t}\\
  \end{bmatrix}$$
  
  The assumptions that we usually make for those shocks is that they are exogenous to each variable, meaning that they are uncorrelated with each. We also assume that they have a mean of 0 and a variance covariance matrix D written as:
  $$\begin{bmatrix}
  \sigma_1^2 & 0 \\
  0 & \sigma_2^2 \\
  \end{bmatrix}$$
  

  B. The reduced form model is written as:
  \begin{align}
  y_t &= B^{-1}\Gamma_0+B^{-1}\Gamma_1y_{t-1}+B^{-1}\epsilon_t \\
  &= C + \Phi y_{t-1} + e_t
  \end{align}
  
  Assuming that our structural VAR model is of the form:
  \begin{align}
  By_t &=  \Gamma_0+\Gamma_1y_{t-1}+\epsilon_t
  \end{align}
  
  The assumptions that we make is that $\beta_{12}\neq \beta_{21} \neq |1|$ so that the inverse of the $B$ matrix, representing the coefficients, exists. 
  
  The reduced form shocks in relation to the structural one is given by: 
  \begin{align}
  e_t &= B^{-1}\epsilon_t\\
  &= \frac{1}{1-\beta_{12}\beta_{21}} \begin{bmatrix} 1 & \beta_{12} \\ \beta_{12} & 1 \end{bmatrix} \begin{bmatrix} \epsilon_{1t}\\ \epsilon_{2t} \end{bmatrix} \\
  &= \frac{1}{1-\beta_{12}\beta_{21}}  \begin{bmatrix} \epsilon_{1t} & \beta_{12}\epsilon_{2t} \\ \beta_{12}\epsilon_{1t} & \epsilon_{2t} \end{bmatrix} \\
  &= \begin{bmatrix}
  e_{1t}\\
  e_{2t}\\
  \end{bmatrix}
  \end{align}
  
  WHere $\frac{1}{1-\beta_{12}\beta_{21}}$ represents the overall feedback effect. The assumption that we make is that any forecast errors has the form of the linear combination of structural shocks. This means that shocks to income affect shocks to money which in turn affects shocks to income etc...
This implies that the variance covariance matrix is not going to be diagonal as both the forecast errors are affected by both shocks. Therefore, we write the variance covariance matrix as:

\begin{align}
E[e_t] &= 0 \\
E[e_t e_t'] &= E[B^{1}\epsilon_t\epsilon_t'(B^{-1})'] \\
&= B^{-1}E[\epsilon_t\epsilon_t'](B^{-1})' \\
&= B^{-1}D(B^{-1})'
\Omega &= \begin{bmatrix}
  \omega_{11} & \omega_{12} \\
  \omega_{21} & \omega_{22} \\
  \end{bmatrix}
\end{align}
  
Since we know that $\Omega$ is not a diagonal matrix, it cannot be the case that $\omega_{21}=\omega_{12} = 0$. Furthermore, we also know that the matrix is positive definite symmetric. From the reduced form VAR we $\Omega$ however we want to find $B$ and $D$. For that we will use the Cholesky decomposition. 
  
 
  
  C. If we were to suppose that $B^{-1}$ was a "lower triangular" matrix, meanig that the upper right corner of matrix is full of zeroes, then we could identify $B$ and $D$ from the Cholesky decomposition. The Cholesky decomposition states that for any positive symmetric matrix, i.e. $\Omega$ there exists a unique decomposed triangular factorization such that:
  \begin{align}
  \Omega= T\Delta T'
  \end{align}
 
 Where $\Delta$ is a diagonal matrix and $T$ is a lower triangular matrix with 1s on the diagonal. Remember the Cholesky decomposition is unique. We use it in our example because it solves the identification problem. As we can see from the forecast error we have a never ending cycle of structural shocks affecting the forecast errors. This means that it makes it impossible to identify the $\epsilon s$ from the forecast errors $e s$, which is what we want to identify. We know that this decomposition gives us the parameters that we want to get by this simple proof. 
 Let us assume that $T=B^{-1}$ and that $\Delta=D$ so that $\Omega = B^{-1}D(B^{-1})'$. Since we assume that $B^{-1}$ is a lower triangular matrix, it must be the case that:
 \begin{align}
  B^{-1} &= \begin{bmatrix} 1 & \beta_{12} \\ \beta_{12} & 1 \end{bmatrix} \\
  &= \begin{bmatrix} 1 & 0 \\ \beta_{12} & 1 \end{bmatrix} 
  \end{align}
 where $\beta_{12}=0$ so that we do indeed get a lower diagonal matrix. 
 
 Now consider the forecast errors, we know that they are given by 
 \begin{align}
 \begin{bmatrix}
  e_{1t}\\
  e_{2t}\\
  \end{bmatrix} &= \frac{1}{1-\beta_{12}\beta_{21}}  \begin{bmatrix} \epsilon_{1t} & \beta_{12}\epsilon_{2t} \\ \beta_{12}\epsilon_{1t} & \epsilon_{2t} \end{bmatrix} 
  \end{align}
 
 Since we know that $\beta_{12} =0$ we have that: 
 \begin{align}
 e_{1t} &= \epsilon_{1t} \\
 e_{2t} &= \epsilon_{2t} + \beta_{21}\epsilon_{1t}
\end{align}
  We have solved our identification issue. However, as we can see, it is very important that we think carefully about the order of our variables. As we can see here, we find that the forecast error for the second equation is based on the structural shock of the first equation, with some $\beta$ coefficient. Thus we identify the forecast errors recursively. If we were to change the order of the variables, we change the meaning of what we are trying to find. 
  
  D. The matrix $A_0$ looks like this after imposing the necessary short run restrictions:
  $$
  \begin{bmatrix}
  a & 0 & 0 \\
  -b & c & 0 \\
  -d & -e & f \\
  \end{bmatrix}
  $$
Where $a=c=f=1$ 
  
### II) Short Run Restrictions

  A. The intuition of the restrictions imposed in the case of the Killian VAR example is that oil production does not respond within the month to world demand and oil prices, thus it is the first equation in the VAR. World demand on the other hand is affected by oil production within the month, but not by oil demand shocks, so it would be the second equation in the VAR. Lastly, the real oil price is explained by oil production and world demand immediately thus it will be the last equation in this VAR. This intuition makes sense. Oil production cannot change immediately there is some sort of costly production adjustment. World demand on the other hand is contemporaneously affected within the month by oil production as companies can cut back on their oil usage. However, oil demand shocks do not affect it because there is sluggish real economic activity response after the oil price increase. The real price of oil is directly impacted by both these factors immediately.       
  
 B. The reduced form VAR model is:
 \begin{align}
 z_t=A_0^{-1}\alpha+\sum^{24}_{i=1}A_0^{-1}A_iz_{t-i}+A^{-1}_0\epsilon_t
 \end{align}
 
 THe reduced form shocks as we can see from above is $A^{-1}_0\epsilon_t$. Written out we get:
 \begin{align}
 e_t &= A^{-1}_0\epsilon_t \\
 &= \begin{bmatrix}
  a & 0 & 0 \\
  b & c & 0 \\
  d & e & f \\
  \end{bmatrix}
  \begin{bmatrix}
  \epsilon_t^{\Delta prod}  \\
  \epsilon_t^{rea}  \\
  \epsilon_t^{ rpo} \\
  \end{bmatrix}
 \end{align}
 
 Thus the the recursive errors formation is:
 \begin{align}
 e_t^{\Delta prod} &= a\epsilon_t^{\Delta prod} \\
 e_t^{rea} &= b\epsilon_t^{\Delta prod} + c\epsilon_t^{rea} \\
 e_t^{rpo} &= d\epsilon_t^{\Delta prod} + e\epsilon_t^{rea} + f\epsilon_t^{ rpo}
 \end{align}
  
  C.The effects that are contemporaneously zero as an effect of the short run restrictions are the graphs d,g,h (respectively, row-column, middle-left, bottom-left, bottom-middle). The reason I say this is because we need to look at the labels of the graph and compare them to the order of our equation. We know from our assumptions that the aggregate demand shock and the oil specific demand shock should not affect oil production within the month. Hence the graphs d and g represent this assumption. Furthermore, we know the the oil-specific demand shock does not affect the real activity contemporaneously. Graph h represents the effect of oil-specific demand on the real economic activity. 
  
  D. According to the graphs, oil supply shocks do no affect real economic activity or the real price of oil, but there is a negative effect on oil production that is significant and persistent. The aggreagate demand shocks does not affect oil production at all, but significantly affects real economic activity and the real price of oil positively in a persistent manner. The oil-specific demand shocks do not affect oil production, they affect real economic activity in the long run but it is not persistent and they affect the real price of oil and it seems to affect it persistently. 
  
  
  